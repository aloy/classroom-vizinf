---
title: Bringing Visual Inference to the Classroom

# to produce blinded version set to 1
blinded: 0

authors: 
- name: Adam Loy
  # thanks: The authors gratefully acknowledge ...
  affiliation: Department of Mathematics and Statistics, Carleton College

keywords:
- Statistics education
- Statistical graphics
- Simulation-based inference
- Visualizing uncertainty
- Lineup protocol

abstract: In the classroom, we traditionally visualize inferential concepts related to inference using static graphics or interactive apps. For example, there is a long history of using apps to visualize sampling distributions. Recent developments in statistical graphics have created an opportunity to bring additional visualizations into the classroom to hone student understanding. Specifically, the lineup protocol [@Buja-2009bd] provides a framework for students see the difference between signal and noise. This protocol involves embedding a plot of observed data in field of null plots. This approach has proved valuable in visualizing randomization/permutation tests, diagnosing models, and even conducting valid inference when distributional assumptions break down. This paper provides an overview of the lineup protocol for visual inference and how it can be used to hone understanding of key statistical topics.

bibliography: classroomVizInf.bib
output: rticles::asa_article
---


```{r emplogit, include=FALSE}
emplogit <- function(x, y, binsize = NULL, ci = FALSE, probit = FALSE, prob = FALSE){
  # x         vector with values of the independent variable
  # y         vector of binary responses
  # binsize   integer value specifying bin size (optional)
  # ci        logical value indicating whether to plot approximate
  #           confidence intervals (not supported as of 02/08/2015)
  # probit    logical value indicating whether to plot probits instead
  #           of logits
  # prob      logical value indicating whether to plot probabilities
  #           without transforming
  #
  # the rest are the familiar plotting options
  
  if (length(x) != length(y))
    stop("x and y lengths differ")
  if (any(y < 0 | y > 1))
    stop("y not between 0 and 1")
  if (length(x) < 100 & is.null(binsize))
    stop("Less than 100 observations: specify binsize manually")
  
  if (is.null(binsize)) binsize = min(round(length(x)/10), 50)
  
  if (probit){
    link = qnorm
    # if (is.null(main)) main = "Empirical probits"
  } else {
    link = function(x) log(x/(1-x))
    # if (is.null(main)) main = "Empirical logits"
  }
  
  sort <- order(x)
  x <- x[sort]
  y <- y[sort]
  a <- seq(1, length(x), by=binsize)
  b <- c(a[-1] - 1, length(x))
  
  prob <- xmean <- ns <- rep(0, length(a)) # ns is for CIs
  for (i in 1:length(a)){
    range <- (a[i]):(b[i])
    prob[i] <- (sum(y[range]) + 0.5) / (length(y[range]) + 1)
    xmean[i] <- mean(x[range])
    ns[i] <- b[i] - a[i] + 1 # for CI 
  }

  # extreme <- (prob == 1 | prob == 0)
  # prob[prob == 0] = min(prob[!extreme])
  # prob[prob == 1] = max(prob[!extreme])

  
  g <- link(prob) # logits (or probits if probit == TRUE)
  
  # linear.fit <- lm(g[!extreme] ~ xmean[!extreme])
  # b0 <- linear.fit$coef[1]
  # b1 <- linear.fit$coef[2]
  
  # loess.fit <- loess(g[!extreme] ~ xmean[!extreme])

  # ggplot(data = NULL) +
    # geom_point(aes(x = xmean, y = g), shape = 1) +
    # geom_abline(intercept = b0, slope = b1, color = I("blue")) +
    # geom_line(aes(x = loess.fit$x, y = loess.fit$fitted)) +
    # labs(x = xlabel, y = ylabel)
  
  data.frame(x = xmean, y = g)
}
```


```{r setup, include=FALSE, cache=TRUE}
library(Sleuth3)  # for data sets
library(dplyr)    # tools for data manipulation
library(infer)    # tools for simulation-based inference
library(ggplot2)  # plotting tools
library(nullabor) # lineup tools
library(broom)    # extracting residuals in tidy way
library(knitr)    # for include_graphics

set.seed(403)
orig_data <- cbind(case0101, replicate = 20)

writing_sim <- 
  case0101 %>%
  specify(Score ~ Treatment) %>% 
  hypothesize(null = "independence") %>%
  generate(reps = 19, type = "permute") %>%
  as_tibble() %>%
  bind_rows(orig_data) %>%
  mutate(.id = sample(20, size = 20, replace = FALSE) %>% rep(each = nrow(case0101)))

writing_sim_means <- writing_sim %>%
  group_by(.id, Treatment) %>%
  summarize(mean = mean(Score))

diff_means_plot <- ggplot(data = case0101) +
  geom_boxplot(mapping = aes(x = Treatment, y = Score, fill = Treatment), alpha = 0.5) +
  geom_point(data = case0101 %>% group_by(Treatment) %>% summarize(Score = mean(Score)), aes(x = Treatment, y = Score)) +
  scale_fill_viridis_d() +
  scale_color_viridis_d() +
  theme_bw() +
  # coord_flip() +
  theme(legend.position = "none")

ggsave(diff_means_plot, filename = "figs/diff_means_plot.pdf", height = 2.5, width = 2.5)
ggsave(diff_means_plot, filename = "figs/diff_means_plot.png")

permute_plot <- writing_sim %>%
  ggplot() +
  geom_boxplot(mapping = aes(x = Treatment, y = Score, fill = Treatment), alpha = 0.5) +
  geom_point(data = writing_sim_means, mapping = aes(x = Treatment, y = mean, group = Treatment)) +
  facet_wrap(~.id, ncol = 5) +
  scale_fill_viridis_d() +
  scale_color_viridis_d() +
  theme_bw() +
  # coord_flip() +
  theme(legend.position = "none")

ggsave(permute_plot, filename = "figs/permute_lineup.pdf")
ggsave(permute_plot, filename = "figs/permute_lineup.png")

data("ex0826", package = "Sleuth3")
mod <- lm(log(Metab) ~ log(Mass), data = ex0826)
# mod <- lm(Yield ~ Rainfall + I(Rainfall^2), data = ex0915)
lm_lineup <- replicate(19, expr = simulate(mod), simplify = FALSE)
lm_lineup[[20]] <- data.frame(sim_1 = log(ex0826$Metab))

lm_lineup <- lapply(lm_lineup, FUN = function(x) {
  broom::augment(lm(x[[1]] ~ log(Mass), data = ex0826))
}) 

lm_lineup <- lm_lineup %>% 
  bind_rows() %>%
  mutate(.sample = rep(1:20, each = nrow(ex0826)),
         .id = sample(20, size = 20, replace = FALSE) %>% rep(., each = nrow(ex0826))) 

residual_lineup <- lm_lineup %>%
  ggplot(aes(x = .fitted, y = .resid)) +
  geom_hline(yintercept = 0, linetype = 2) +
  geom_point(shape = 1) +
  facet_wrap(~ .id) +
  labs(x = "Fitted values", y = "Residuals") +
  theme_bw()

ggsave(residual_lineup, filename = "figs/residual_lineup.pdf")


observed_residual <- augment(mod) %>%
  ggplot(aes(x = .fitted, y = .resid)) +
  geom_hline(yintercept = 0, linetype = 2) +
  geom_point(shape = 1) +
  labs(x = "Fitted values", y = "Residuals") +
  theme_bw()

ggsave(observed_residual, filename = "figs/observed_residual.pdf", height = 2, width = 2)


set.seed(1523613829)
n <- 30
obs_sim <- rchisq(n, df = 2) 
norm_sims <- lapply(1:19, function(x) rnorm(n))
qq_lineup <- data.frame(x = c(unlist(norm_sims), scale(obs_sim)), .sample = rep(1:20, each = n)) %>%
  mutate(.id = sample(20, size = 20, replace = FALSE) %>% rep(., each = n))

qqplot_lineup <- qq_lineup %>%
  ggplot(aes(sample = x)) +
  geom_qq() + 
  geom_qq_line(linetype = 2) +
  facet_wrap(~.id, ncol = 5) +
  theme_bw() + 
  labs(x = "N(0, 1) quantiles", y = "Sample quantiles")

ggsave(qqplot_lineup, filename = "qqplot_lineup.pdf")
ggsave(qqplot_lineup, filename = "qqplot_lineup.png")

library(arm)
wells <- read.table("data/wells.dat")
wells$dist100 <- wells$dist/100
well_glm <- glm(switch ~ arsenic, family = binomial, data = wells)
well_aug <- augment(well_glm, type.residuals = "deviance")

well_pearson_resid <- 
  well_aug %>%
  ggplot(aes(x = .fitted, y = .resid)) +
  geom_hline(yintercept = 0, linetype = 2) +
  geom_point(shape = 1) +
  labs(x = "Linear predictor", y = "Deviance residuals") +
  theme_bw()

well_lineup <- replicate(19, expr = simulate(well_glm), simplify = FALSE)
well_lineup[[20]] <- data.frame(sim_1 = wells[["switch"]])

well_lineup <- lapply(well_lineup, FUN = function(x) {
  broom::augment(glm(x[[1]] ~ arsenic, data = wells, family = binomial))
}) 

well_lineup <- well_lineup %>% 
  bind_rows() %>%
  mutate(.sample = rep(1:20, each = nrow(wells)),
         .id = sample(20, size = 20, replace = FALSE) %>% rep(., each = nrow(wells))) 

wells_residuals <- well_lineup %>%
  ggplot(aes(x = arsenic, y = .resid)) +
  geom_hline(yintercept = 0, linetype = 2) +
  geom_point(shape = 1, alpha = 0.5) +
  facet_wrap(~ .id) +
  labs(x = "Linear predictor", y = "Deviance residuals") +
  theme_bw()

br <- data.frame(binned.resids(well_aug$arsenic, well_aug$.resid)$binned)

binned_resid_example <- 
  br %>%
  ggplot(aes(xbar, ybar )) +
  geom_hline(yintercept = 0, linetype = 2) +
  geom_point(shape = 1) +
  theme_bw() +
  labs(x = "Predictor", y = "Average deviance residual")
ggsave(binned_resid_example, filename = "figs/binned_resid_example.pdf", height = 2.5, width = 2.5)
ggsave(binned_resid_example, filename = "figs/binned_resid_example.png")

# Working on the binned residual plots
binned_resid_lineup <- well_lineup %>%
  group_by(.sample) %>%
  group_map(~ data.frame(binned.resids(.x$arsenic, .x$.resid)$binned)) %>%
  bind_rows(.id = ".sample") %>%
  mutate(
    .id = sample(20, size = 20, replace = FALSE) %>% rep(., each = 54)
  )

wells_binned_residuals <- binned_resid_lineup %>%
  ggplot(aes(x = xbar, y = ybar)) +
  geom_hline(yintercept = 0, linetype = 2) +
  geom_point(shape = 1) +
  facet_wrap(~ .id) +
  labs(x = "Linear predictor", y = "Binned deviance residuals") +
  theme_bw()

ggsave(wells_binned_residuals, filename = "figs/wells_binned_residuals.pdf")


# emplogit(x = wells$arsenic, y = wells$switch, xlab = "Predictor")

emp_logit_lineup_data <-
  well_lineup %>%
  group_by(.sample) %>%
  group_map(~emplogit(x = .$arsenic, y = .[[1]])) %>%
  bind_rows(.id = ".sample") %>%
  mutate(
    .id = sample(20, size = 20, replace = FALSE) %>% rep(., each = 61)
  )

emp_logit_lineup <-
  emp_logit_lineup_data %>%
  ggplot(aes(x = x, y = y)) +
  geom_point(shape = 1) +
  # geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~ .id) +
  labs(x = "X", y = "Empirical logit") +
  theme_bw()

ggsave(emp_logit_lineup, filename = "figs/emp_logit_lineup.pdf")
```


# Introduction

<!--Explain that the problem is and what my proposed solution is. Be sure to review pertinent literature. -->

Could I use the GAISE guidelines to frame the start of this introduction???

- Recommendation 1: Teach statistical thinking
    + simulation-based inference has helped here
- Recommendation 2: Focus on conceptual understanding
    + simulation-based inference has helped here
    + applets help students visualize resampling, but not always the big picture idea behind inference... that's where sesame-street logic comes into play...
- Recommendation 5: Use technology to explore concepts and
analyze data
    + apps help
    + lot's of great options (StatKey, Rossman/Chance, Many Shiny apps...)


Can we link to hypothetical outcome plots somehow?? Essentially we get 19ish hypothetical outcomes under a model...




Recent years have seen a great deal of innovation in how we teach statistics as we strive to overcome what @Cobb-2007uo termed "the tyranny of the computable." Most notably, simulation-based pedagogies for the first course have been proposed and validated [@Cobb-2007uo; @Tintle-2011vo; @Tintle-2012td; @Maurer-2014te; @Tintle2014-vt]. These simulation-based pedagogies have also been used in mathematical statistics [@chihara2011; @Cobb2011-vz], and @Tintle2015-yv argue that they should be used throughout the entire curriculum. 



In addition to changes in how we introduce inference, there have also been changes in 


Additionally, the GAISE guidelines have led instructors to use visualization to grapple with higher-dimensional data sets and messier data...

Something about apps...

Something about sampling distributions...

The goal of this article is to discuss how to incorportate visual inference into your classroom to help your students differentiate between different forms of signal and noise, and better understand the nuances of statistical significance. Section \ref{sec:vizinf} presents an overview of visual inference, specifically the lineup protocol. Section \ref{sec:intro} presents examples of how the lineup protocol can be used in the first course, and Section \ref{sec:othercourses} presents additional examples throughout the curriculum. We conclude with a brief summary and discussion in Section \ref{sec:discussion} 


\section{Visual inference}
\label{sec:vizinf}

As outlined by @Cobb-2007uo, most introductory statistics books teach that classical hypothesis tests consist of 
(i) formulating  null and alternative hypotheses, 
(ii) calculating a test statistic from the observed data,
(iii) comparing the test statistic to a reference (null) distribution,
and (iv) deriving a $p$-value on which a conclusion is based.
This is still true for the first course after adapting it to address the new GAISE guidelines  regardless of whether a simulation-based approach is used [cf. @Lock2012; @tintle2015; @introstats].


The *lineup protocol* for visual inference has a direct analog for each of these four steps, as outlined by @Buja-2009bd. As a first example of visual inference via the lineup protocol, consider the creative writing experiment discussed by [@ramsey2013, pp. 2--14]. The experiment was designed to exploer whether creativity scores were impacted by the type of motivation (intrinsic or extrinsic). To do this creative writers were randomly assigned to a questionnaire where they ranked reasons they write: one questionnaire listed intrinsic motivations and the other listed extrinsic motivations. After completing the questionnaire, all subjects wrote a Haiku about laughter which was graded for creativity by a panel of poets. @ramsey2013 discuss how to conduct a permutation test for the difference in mean creativity scores between the two treatment groups. Below, we illustrate the steps of a visual test.

1. A visual test begins identically to a traditional hypothesis test, by clearly stating the competing claims about the model/population parameters. In a first course, this could be written as: $H_0: \mu_{\rm intrinsic} - \mu_{\rm extrinsic} = 0$ vs. $H_0: \mu_{\rm intrinsic} - \mu_{\rm extrinsic} \ne 0$. 

2. The test statistic is a plot displaying an aspect of the data or model that allows the observer to differentiate scenarios under the null hypothesis from scenarios under alternative hypotheses. Here, side-by-side boxplots, or faceted histograms or density plots are reasonable choices to display the relevant aspects of the distribtions. Figure \ref{fig:data_plot} are boxplots of the original creative writing scores by treatment group where a dot is used to represent the sample mean for each group.

```{r echo=FALSE, fig.cap="\\label{fig:data_plot} Boxplots of the original creative writing scores by treatment group. The dot represents the mean of each group."}
knitr::include_graphics("figs/diff_means_plot.pdf")
```

3. *Null plots* are generated consistently with the null hypothesis and the set of all null plots constitutes the reference distribution. To facilitate comparison of the data plot to the null plots, the data plot should be randomly situtated in the field of null plots. This arrangement of plots is called a *lineup*. Figure \ref{fig:lineup} shows one possible lineup for the creative writing experiment. The 19 null plots were generated via permutation resampling, and the data plot was randomly assigned to panel #4. 

```{r echo=FALSE, fig.cap="\\label{fig:lineup} A lineup consisting of 19 null plots generated via permutation resampling and the original data plot for the creative writing study. The data plot was randomly placed in panel #4."}
knitr::include_graphics("figs/permute_lineup.pdf")
```

4. If the null hypothesis is true, then we expect the data plot to be indistinguishable from the null plots.  Thus, is one is able to identify the data plot in panel #4 of Figure \ref{fig:lineup}, then this provides evidence against the null hypothesis. If one wishes to calculate a *visual p-value*, then lineups need to be presented to a number of independent observers for evaluation. While this is possible, we will not discuss this process as the pedagaogical value of the lineup protocol is in visualizing signal and noise.



\section{Using visual inference in introductory statistics}
\label{sec:intro}

In this section, we discuss how to incorportate the lineup protocol into your classroom to clarify common points of confusion. The goal is to provide examples of how this could be done, not to provide an exhaustive list of possibilities.


## Introducing (simulation-based) inference

The strong parallels between visual inference and classical hypothesis testing make it a natural way to introduce the idea of statistical significance without getting bogged down in the minutia of $p$-values. In this section, we will outline how we use visual inference to introduce the concepts behind hypothesis testing without devling into formal details. To do this, we will continue to discuss the reative writing experiment introduced in Section \ref{sec:vizinf}.






## Interpreting unfamiliar plots

<!-- SHOULD I ONLY INCLUDE ONE PLOT TYPE AND SIMPLY MENTION THE OTHER? -->

A second way to utilize visual inference in the first course is to help students build intuition about new and unfamiliar plot types. Two plot types that we have found introductory students struggle to interpret are the normal quantile-quantile (Q-Q) plot and the residual plot. In both situations, the lineup protocol helps students tune their understanding of what constitutes an "interesting" pattern (i.e. signal). 


### Q-Q plots

Teaching a novice to interpret a normal Q-Q plot is no easy task, especially in an algebra-based first course where students can get lost in the calculation of quantiles rather than focusing on the bigger picture. Further, Q-Q plots already suffer from a perception problem, since humans have a tendency to evaluate the shortest (i.e. orthogonal) distance, even when asked to evaluate vertical distances [@cleveland:1984; @robbins:2005; @sineillusion]. While a detrended version of the Q-Q plot has been proposed to overcome this difficulty [@Loy2016-fg], the plot still requires students to calibrate their intuition. In this paper we will discuss "classical" Q-Q plots for simplicity.


...show for smaller sample sizes... do i need to cite meeker and cook??....


### Residual plots

Interpreting residual plots is also fraught with common errors. We have found that, regardless of our valient attempts to explain what "random noise" or "random deviations from a model" might look like, there is no substitute for first hand experience. In this section we outline a class activity/discussion that we use to help train students to interpret residual plots. The full activity can be found in the supplemental materials.

To begin, we have students fit a simple linear regression model, write down what a residual is (in both words and using notation), and then create a first residual plot, such as Figure \ref{fig:residplot}. Next, we pose the question:  "Does this residual plot provide evidence of a model deficiency?" This provides students time to formalize their decision, especially what features of the residual plot they based their decision upon. 

```{r residual plot, echo=FALSE, fig.align='center', fig.cap="\\label{fig:residplot} A residual plot for a simple linear regression model. Is there evidence that the model is insufficient?"}
knitr::include_graphics("figs/observed_residual.pdf")
```

Once students have carefully interpreted the observed residual plot, we have them generate a lineup where their data plot has been randomly embedded in a field of null plots, as shown in Figure \ref{fig:lineupresid}. Here, the null plots have been generated using the parametric bootstrap, but the residual or non-parametric bootstraps are other viable choices. We avoid the details of how the null plots were generated, but this depends on the goals for your class. Once the lineup has been generated, we ask students to (i) identify which panel contains the observed residual plot, (ii) describe patterns they observed in three null plots, and (iii) decide whether/how the observed residual plot is systematically different from the null plots.

```{r residual lineup, echo=FALSE, fig.cap="\\label{fig:lineupresid} A lineup of residual plots. The null plots are generated via a parametric bootstrap from the fitted model. The observed data are shown in panel #9."}
knitr::include_graphics("figs/residual_lineup.pdf")
```


Teaching tips...

- In the above example, the observed residual plot in panel #9 is systematically different from the null plots. While this is one example we use in class, we also recommend a parallel example where there is no discrepancy between the data and the model.

- Depending on your prefernce and goals, follow-up discussions about the design of residual plots could be injected to the end of this activity. For example, you could provide students with a second version of the lineup where LOESS smoothers have been added to each panel and ask students what features of the residual plot this highlights.

- An alternative approach would be to have students first use the Rorschach protocol to look through a series of null plots, describing what they see, and then look at a single residual plot.



\section{Using visual inference in other courses}
\label{sec:othercourses}

The utility of visual inference is not restricted to introductory courses. We have found that whenever a new model is encountered intuition about diagnostic plots must be rebuilt. As an example we will consider diagnostics for binary logistic regression models, a common topic in a second course.

Interpreting residual plots from binary logistic regression is extremely difficult, as plots of the residuals against the fitted values or predictors often look similar for adequate and inadequate models. The lineup protocol provides a framework to have this dicussion. For example, you can simulate one data set that is appropriate for binary logistic regression and one that violates the linearity of the logit, and have your students try to identify the data plot in each situation. 

After establishing the pitfalls of "conventional" residual plots for binary logistic regression, you can turn to alternative strategies, again using the lineup to calibrate student intution with new plot types. Below we present two examples.

*Binned residuals.* @GelmanHill:2007 recommend using binned residual plots to explore possible violations of linearity for binary logistic regression. A binned residual plot is created by calculating the average residual for a number of bins along the $x$-axis. Figure \ref{fig:binned} shows an example from a simple binary logistic regression model where the average deviance residual is plotted on the $y$-axis for each of 54 bins on the $x$-axis. The bins were set as with a histogram, and $\lfloor \sqrt{n} \rfloor$. @GelmanHill:2007 claim that these plot should behave much like the familiar standardized residual plots from regression. If this is the case, then Figure \ref{fig:binned} is indicative of nonlinearity. However, rather than simply citing @GelmanHill:2007, a lineup empowers students to investigate the behavior of this new plot type. A lineup for these residuals is given in Figure \ref{fig:binnedlineup}. As suspected, the data plot (panel #8) clearly stand out from the field of null plots.

```{r echo=FALSE, fig.cap="\\label{fig:binned} A binned residual plot from a simple binary logistic regression model. The average deviance residual is plotted on the $y$-axis for each of 54 bins on the $x$-axis."}
knitr::include_graphics("figs/binned_resid_example.pdf")
```

```{r echo=FALSE, fig.cap="\\label{fig:binnedlineup} A lineup of binned residual plots from a simple binary logistic regression model. The observed residuals are shown in panel #8 and clearly stand out from the field of null plots, indicating a problem with linearity."}
knitr::include_graphics("figs/wells_binned_residuals.pdf")
```

*Empirical logit plots.* A more-common alternative to the binned residual plot is the empirical logit plot... 

Need to define briefly...

Something about small sample sizes and difficulty interpreting... Let's use one of the Stat2 example here... it should be well-known enough...

```{r echo=FALSE, fig.cap="\\label{fig:emplogitlineup} A lineup of empirical logit plots from a simple binary logistic regression model. The observed residuals are shown in panel #17 and clearly stand out from the field of null plots, indicating a problem with linearity."}
knitr::include_graphics("figs/emp_logit_lineup.pdf")
```


In this section we focused on using visual inference to help diagnose logistic regression models, but the approach is more general. If you have a plot highlighting some feature(s) of the fitted model, then after simulating data from a "correct" model (i.e. one without model deficiencies), you can create a lineup to interrogate the model. For example, \cite{Loy2017-fo} discuss how visual inference can be used to diagnose multilevel models. 


# Discussion
\label{sec:discussion}

MENTION PEDAGOGICAL CONSIDERATIONS NOT YET DISCUSSED, HOW TO IMPLEMENT IN SOFTWARE OR AN APP, IN CLASS V. HOMEWORK, ETC.

A BRIEF GO AND DO PARAGRAPH TO REITERATE THE MESSAGE



# References